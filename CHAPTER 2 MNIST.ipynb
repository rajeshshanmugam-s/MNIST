{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_imgaes, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgaes\n",
    "# Images are encoded in numpy arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgaes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = train_imgaes[1] # Tensor slicing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crop images with the pixel positions, tensor slicing \n",
    "plt.imshow(digit[14:, 14:], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So there are 60000 labels and 60000 Images in trainning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First train images and the train labels are feed into neural networks, so it learn from images and the associated labels. Then it will predict for test_images, we will check test_labels and the predicted_lables are matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rajesh/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Our Network consists of two sequential layers which are densely connected, fully connected. And the second layer 10 way softmax layer, Which outputs array of 10 probilistic socres for our 10 digit labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation part\n",
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to preprocess the data \n",
    "# TODO: Add more points claiming why we need this\n",
    "train_images = train_imgaes.reshape((60000, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape(10000, 28*28,)\n",
    "test_images = test_images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorically encode the labels \n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rajesh/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.2586 - accuracy: 0.9250\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.1055 - accuracy: 0.9688\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0701 - accuracy: 0.9791\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0505 - accuracy: 0.9846\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0389 - accuracy: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe7316d58d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Accuaracy 98.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 29us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9786999821662903"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The difference between the training and the testing accuracy is an example of overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
